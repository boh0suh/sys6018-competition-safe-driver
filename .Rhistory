plotExplanatoryVariables(sce, variables=c("counts_feature_controls_Spike",
"log10_counts_feature_controls_Spike", "sex", "tissue", "age"))
#########################################################################################
## EXPERIMENTING WITH IDF MATRIX
library(readr)
library(stringr)
library(tm)
library(NLP)
library(tidytext)
library(plyr)
library(dplyr)
library(boot)
#convert the gene expression data from the sce to a dataframe
brain<- as.data.frame(sce)
brain3<- as.data.frame(brain)
cell.type<- cell.type[-cell_drop, ]
cbind(brain3, cell.type)
merge(brain3, cell.type)
brain4<- cbind.data.frame(brain3, cell.type)
View(brain4)
brain4["cell.type"]
colnames(brain4)
colnames(brain4[,8950:8957])
brain4["celltype"]
gene_data = brain4
train<- sample(2902, 2000, replace = false)
train<- sample(2902, 2000, replace = FALSE)
gene.train<- gene_data[train, ]
gene.test<- gene_data[-train,]
bag.gene<- randomForest(celltype~., data = gene.train, mtry = 8956, ntree = 150, importance = TRUE)
bag.gene<- randomForest(celltype~., data = gene.train, mtry = 8956, ntree = 150, importance = TRUE, distribution = "binomial")
gene_data = gene_data[ ,1:53]
train<- sample(2902, 2000, replace = FALSE)
gene.train<- gene_data[train, ]
gene.test<- gene_data[-train,]
gene_data = gene_data[ ,c(1:53, 8957)]
train<- sample(2902, 2000, replace = FALSE)
gene.train<- gene_data[train, ]
gene_data = brain4
gene_data = gene_data[ ,c(1:53, 8957)]
train<- sample(2902, 2000, replace = FALSE)
gene.train<- gene_data[train, ]
gene.test<- gene_data[-train,]
bag.gene<- randomForest(celltype~., data = gene.train, mtry = 53, ntree = 150, importance = TRUE)
boost.genes<- gbm(celltype~., data= gene.train, distribution= "gaussian", n.trees = 1000, interaction.depth = 8)
library(randomForest)
library(MASS)
library(tree)
library (ISLR)
library(gbm)
library(boot)
boost.genes<- gbm(celltype~., data= gene.train, distribution= "gaussian", n.trees = 1000, interaction.depth = 8)
unique(gene_data[,8957])
unique(gene_data[ ,8957])
unique(gene_data[ ,54])
for (i in 1:2902) {
ifelse(gene_data[i, 8957] == sscortex, 1, 0) }
for (i in 1:2902) {
ifelse(gene_data[i, 8957] == "sscortex", 1, 0) }
unique(gene_data[,8957])
for (i in 1:2902) {
ifelse(gene_data[i, 54] == "sscortex", 1, 0) }
unique(gene_data[ ,54])
ifelse(gene_data[i, 54] == "sscortex", 1, 0
ifelse(gene_data[i, 54] == "sscortex", 1, 0)
for (i in 1:2902) {
ifelse(gene_data[i, 54] == "sscortex", gene_data[i, 54] ==1, gene_data[i, 54] == 0) }
unique(gene_data[ ,54])
ifelse(gene_data[i, 54] == "sscortex", gene_data[i, 54] == 1, gene_data[i, 54] == 0)
for (i in 1:2902) {
ifelse(gene_data[i, 54] == "sscortex", gene_data[i, 54] = 1, gene_data[i, 54] =0) }
gene_data = brain4
gene_data = gene_data[ ,c(1:53, 8957)]
for (i in 1:2902) {
if (gene_data[i, 54] == "sscortex" ) {gene_data[i, 54] = 1}
else {gene_data[i, 54]= 0}}
unique(gene_data[ ,54])
train<- sample(2902, 2000, replace = FALSE)
gene.train<- gene_data[train, ]
gene.test<- gene_data[-train,]
bag.gene<- randomForest(celltype~., data = gene.train, mtry = 53, ntree = 150, importance = TRUE)
boost.genes<- gbm(celltype~., data= gene.train, distribution= "binomial", n.trees = 1000, interaction.depth = 8)
boost.genes<- gbm(celltype~., data= gene.train, distribution= "binomial", n.trees = 1000, interaction.depth = 4)
untar("Downloads/GSE56638_RAW.tar")
untar("C:/Users/mkw5c/OneDrive/Documents/Capstone/GSE56638_RAW.tar")
data56638<- untar("C:/Users/mkw5c/OneDrive/Documents/Capstone/GSE56638_RAW.tar")
print(data56638)
data56638<- untar("C:/Users/mkw5c/OneDrive/Documents/Capstone/GSE56638_RAW.tar", "C:\Users\mkw5c\OneDrive\Documents\Capstone")
data56638<- untar("C:/Users/mkw5c/OneDrive/Documents/Capstone/GSE56638_RAW.tar", "C:\\Users\\mkw5c\\OneDrive\\Documents\\Capstone")
untar("C:/Users/mkw5c/OneDrive/Documents/Capstone/GSE56638_RAW.tar", "C:\\Users\\mkw5c\\OneDrive\\Documents\\Capstone")
brain_genes<- brain4
brain_genes<- brain2
apply(brain_genes, 2, function(col) mean(col))
write.csv(brain2, "C:\\Users\\mkw5c\\OneDrive\\Documents\\Capstone\\r codes\\brain2.csv")
?write_csv
library(readr)
library(stringr)
library (tm)
library (topicmodels)
library(XML)
library(randomForest)
library(MASS)
library(tree)
library (ISLR)
library(gbm)
library(boot)
brain_genes<- read_csv("C:\\Users\\mkw5c\\OneDrive\\Documents\\Capstone\\r codes\\brain2.csv")
View(brain_genes)
apply(brain_genes[,2:8906], 2, function(col) mean(col))
gene_means = apply(brain_genes[,2:8906], 2, function(col) mean(col))
?apply
gene_means = as.vector(apply(brain_genes[,2:8906], 2, function(col) mean(col)))
make_binary<- function(x, y) {
ifelse (x > y, 1, 0)
}
for (i in 1:8906){
apply(brain_genes[,i], 1, make_binary, y = gene_means[i] )}
make_binary<- function(x, y) {
if(x >= y) {x == 1}
else {x ==0}
}
10%%10
make_binary<- function(x, y) {
if(x >= y) {x = 1}
else {x=0}
}
for (i in 1:8906){
if (i%%10 == 0) {print(i)}
apply(brain_genes[,i], 1, make_binary, y = gene_means[i] )}
View(brain_genes)
x = 0
if(4>=2){x == 1} else {x == 0}
if(4>=2){x = 1} else {x =0}
x
x = 4
y = 2
if(x>=2y){x = 1} else {x =0}
x = 4
y = 2
if(x>=y){x = 1} else {x =0}
x
brain_genes<- brain_genes[ ,2:8906]
gene_means = as.vector(apply(brain_genes, 2, function(col) mean(col)))
make_binary<- function(x, y) {
if(x >= y) {x = 1} else {x=0}
}
if(brain[1, 2]>=gene_means[2]){brain_genes[1,2] = 1} else {brain_genes[1,2] =0}
brain[1, 2]
if(brain_genes[1, 2]>=gene_means[2]){brain_genes[1,2] = 1} else {brain_genes[1,2] =0}
brain_genes[1, 2]
brain_genes<- read_csv("C:\\Users\\mkw5c\\OneDrive\\Documents\\Capstone\\r codes\\brain2.csv")
brain_genes<- brain_genes[ ,2:8906]
gene_means = as.vector(apply(brain_genes, 2, function(col) mean(col)))
make_binary<- function(x, y) {
if(x >= y) {x = 1} else {x=0}
}
for (i in 1:8906){
if (i%%10 == 0) {print(i)}
apply(brain_genes[,i], 1, make_binary, y = gene_means[i] )}
for (i in 1:8905){
if (i%%10 == 0) {print(i)}
apply(brain_genes[,i], 1, make_binary, y = gene_means[i] )}
unique(brain_genes[,])
View(brain_genes)
gene_meds = as.vector(apply(brain_genes, 2, function(col) median(col)))
for (i in 1:2902)
for (i in 1:2902) {
if (brain_genes[i, 1] >= gene_meds[1]) {
brain_genes[i, 1] = 1}
else {brain_genes[i,1] = 0}}
View(brain_genes)
gene_means = as.vector(apply(brain_genes, 2, function(col) mean(col)))
make_binary<- function(x, y) {
if(x >= y) {x = 1} else {x=0}
}
brain_genes<- read_csv("C:\\Users\\mkw5c\\OneDrive\\Documents\\Capstone\\r codes\\brain2.csv")
brain_gene_df<- brain_genes[ ,2:8906]
gene_means = as.vector(apply(brain_gene_df, 2, function(col) mean(col)))
make_binary<- function(x, y) {
if(x >= y) {x = 1} else {x=0}
}
for (i in 1:2902) {
if (brain_gene_df[i, 1] >= gene_means[1]) {
brain_gene_df[i, 1] = 1}
else {brain_gene_df[i,1] = 0}}
View(brain_gene_df)
apply(brain_gene_df[,2], 1, make_binary, y = gene_means[2])
View(brain_gene_df)
make_binary<- function(x, y) {
ifelse (x >= y, 1, 0)
}
apply(brain_gene_df[,2], 1, make_binary, y = gene_means[2])
brain_gene_df[,2]<-apply(brain_gene_df[,2], 1, make_binary, y = gene_means[2])
View(brain_gene_df)
brain_gene_df<- brain_genes[ ,2:8906]
gene_means = as.vector(apply(brain_gene_df, 2, function(col) mean(col)))
make_binary<- function(x, y) {
ifelse (x >= y, 1, 0)
}
for (i in 1:8905){
if (i%%10 == 0) {print(i)}
apply(brain_gene_df[,i], 1, make_binary, y = gene_means[i] )}
View(brain_gene_df)
for (i in 1:8){
if (i%%10 == 0) {print(i)}
brain_gene_df[,i] <-apply(brain_gene_df[,i], 1, make_binary, y = gene_means[i] )}
View(brain_gene_df)
make_terms<- function(x) {
ifelse (x == 1, colnames(x), na)
}
apply(brain_gene_df[,2], 1, make_terms)
genes = as.vector(colnames(brain_genes_df))
genes = as.vector(colnames(brain_gene_df))
make_terms<- function(x, y) {
ifelse (x == 1, y, na)
}
apply(brain_gene_df[,2], 1, make_terms, y = genes[2])
make_terms<- function(x, y) {
ifelse (x == 1, y, NA)
}
apply(brain_gene_df[,2], 1, make_terms, y = genes[2])
make_terms_fast<- function(x, y, z) {
ifelse (x >= y, z, NA)
}
apply(brain_gene_df[,9], 1, make_terms_fast, y = gene_means[9],z = genes[9])
brain_gene_df<- brain_genes[ ,2:8906]
gene_means = as.vector(apply(brain_gene_df, 2, function(col) mean(col)))
make_terms_fast<- function(x, y, z) {
ifelse (x >= y, z, NA)
}
for (i in 1:8){
if (i%%10 == 0) {print(i)}
brain_gene_df[,i] <-apply(brain_gene_df[,i], 1, make_terms_fast, y = gene_means[i], z = genes[i] )}
View(brain_gene_df)
library (R.utils)
library (gdata)
#source("https://bioconductor.org/biocLite.R")
#biocLite("scater")
library (scater)
library (scran)
library (readr)
############################### BRAIN CELLS ##################################################
## COUNT LOADING
readFormat <- function(infile) {
# First column is empty.
metadata <- read.delim(infile, stringsAsFactors=FALSE, header=FALSE, nrow=10)[,-1]
rownames(metadata) <- metadata[,1]
metadata <- metadata[,-1]
metadata <- as.data.frame(t(metadata))
# First column after row names is some useless filler.
counts <- read.delim(infile, stringsAsFactors=FALSE, header=FALSE, row.names=1, skip=11)[,-1]
counts <- as.matrix(counts)
return(list(metadata=metadata, counts=counts))
}
# READ IN THE COUNTS FOR EACH TYPE OF GENE
endo.data <- readFormat("C:/Users/mkw5c/OneDrive/Documents/Capstone/MRNA LUN.txt")
spike.data <- readFormat("C:/Users/mkw5c/OneDrive/Documents/Capstone/ERCC LUN.txt")
mito.data <- readFormat("C:/Users/mkw5c/OneDrive/Documents/Capstone/MITO LUN.txt")
cell.type<- read_csv("C:/Users/mkw5c/OneDrive/Documents/Capstone/cell types.csv")
#REFORMAT MITO DATA TO BE CONSISTENT WITH OTHERS
m <- match(endo.data$metadata$cell_id, mito.data$metadata$cell_id)
mito.data$metadata <- mito.data$metadata[m,]
mito.data$counts <- mito.data$counts[,m]
#CREATE SINGLE MATRIX FOR SCESET OBJECT AND INCLUDE METADATA ##WHAT IS AN SCESET OBJECT
all.counts <- rbind(endo.data$counts, mito.data$counts, spike.data$counts)
metadata <- AnnotatedDataFrame(endo.data$metadata)
sce <- newSCESet(countData=all.counts, phenoData=metadata)
dim(sce)
#ADD ROWS TO ANNOTATE MITOCHONDRIA AND SPIKES
nrows <- c(nrow(endo.data$counts), nrow(mito.data$counts), nrow(spike.data$counts))
is.spike <- rep(c(FALSE, FALSE, TRUE), nrows)
is.mito <- rep(c(FALSE, TRUE, FALSE), nrows)
#### QUALITY CONTROL
sce<- calculateQCMetrics(sce, feature_controls = list(Spike = is.spike, Mt = is.mito))
setSpike(sce)<- "Spike"
#look at library sizes and number of genes expressed
par(mfrow = c(1,2))
hist(sce$total_counts/1e3, xlab = "Library sizes (thousands)", main = "", breaks = 20, col = "grey80", ylab = "Number of Cells")
hist(sce$total_features, xlab = "Number of Expressed Genes", main = "", breaks = 20, col = "grey80", ylab = "Number of Cells")
#The spike-in proportions here are more variable than in the
#HSC dataset. This may reflect a greater variability in the total
#amount of endogenous RNA per cell when many cell types are present.
par(mfrow = c(1,2))
hist(sce$pct_counts_feature_controls_Mt, xlab = "Mitochondrial proportion (%)",
ylab="Number of cells", breaks=20, main="", col="grey80")
hist(sce$pct_counts_feature_controls_Spike, xlab="ERCC proportion (%)",
ylab="Number of cells", breaks=20, main="", col="grey80")
## remove small outliers from library size and gene expression
cell_drop<-c(which( isOutlier(sce$total_counts, nmads=3, type="lower", log=TRUE)))
libsize.drop <- isOutlier(sce$total_counts, nmads=3, type="lower", log=TRUE)
cell_drop<- c(cell_drop, which(isOutlier(sce$total_features, nmads=3, type="lower", log=TRUE)))
feature.drop <- isOutlier(sce$total_features, nmads=3, type="lower", log=TRUE)
## remove large outliers form spikes and mito
cell_drop<- c(cell_drop, which(isOutlier(sce$pct_counts_feature_controls_Mt, nmads=3, type="higher")))
mito.drop <- isOutlier(sce$pct_counts_feature_controls_Mt, nmads=3, type="higher")
cell_drop<- c(cell_drop, which(isOutlier(sce$pct_counts_feature_controls_Spike, nmads=3, type="higher")))
spike.drop <- isOutlier(sce$pct_counts_feature_controls_Spike, nmads=3, type="higher")
cells<- cell.type[-cell_drop,]
write.csv(cells, "C:/Users/mkw5c/OneDrive/Documents/Capstone/cells2902.csv")
##  remove low quality cells by combining filters for all metrics
sce <- sce[,!(libsize.drop | feature.drop | spike.drop | mito.drop)]
data.frame(ByLibSize=sum(libsize.drop), ByFeature=sum(feature.drop),
ByMito=sum(mito.drop), BySpike=sum(spike.drop), Remaining=ncol(sce))
## use UMI's to get rid of low abundance genes: eliminate technical noise from
## amplification biases
ave.counts <- rowMeans(counts(sce))
hist(log10(ave.counts), breaks=100, main="", col="grey",
xlab=expression(Log[10]~"average count"))
#use the histogram to choose a count threshold
keep <- rowMeans(counts(sce)) >= 0.2
abline(v=log10(0.2), col="blue", lwd=2, lty=2)
sce<- sce[keep, ]
nrow(sce)
###reduced our features from 20063 to 8939
#eliminate highly variable mitochondrial genes
sce <- sce[!fData(sce)$is_feature_control_Mt,]
nrow(sce)
###Normalization of Cell Specific Biases
# cluster similar cells together and normalize the cells in each cluster using the
# deconvolution method. This improves normalization accuracy by reducing the number
# of DE genes between cells in the same cluster
clusters <- quickCluster(sce)
sce <- computeSumFactors(sce, cluster=clusters) #this line is the deconvolution method
plot(sizeFactors(sce), sce$total_counts/1e3, log="xy",
ylab="Library size (thousands)", xlab="Size factor")    #these size factors are from the deconv.
#deconvolve spikes
sce <- computeSpikeFactors(sce, type="Spike", general.use=FALSE)
#normalize by size factor
sce <- normalize(sce)
#look at which technical factors may be explaining variability in the data
plotExplanatoryVariables(sce, variables=c("counts_feature_controls_Spike",
"log10_counts_feature_controls_Spike", "sex", "tissue", "age"))
#########################################################################################
## EXPERIMENTING WITH IDF MATRIX
library(readr)
library(stringr)
library(tm)
library(NLP)
library(tidytext)
library(plyr)
library(dplyr)
library(boot)
#convert the gene expression data from the sce to a dataframe
brain<- as.data.frame(sce)
brain3<- as.data.frame(brain)
cell.type<- cell.type[-cell_drop, ]
brain4<- cbind.data.frame(brain3, cell.type)
brain4["celltype"]
#convert the brain dataframe to a document corpus
#gene_corpus = VCorpus(DataframeSource(brain))
#gene_corpus[[1]]$content
#create a matrix of idf scores
sum(brain[,1] > 0)
#find the number of cells that are positive for each gene
numcellspos<- rep(0, 8956)
for (i in 1:8956) {
numcellspos[i]<- sum(as.numeric(brain[,i])>0)
}
print(numcellspos[1:10])
#find the idf weight for each gene
idf<- function(n, npos) {
log(n/npos)
}
idf_scores<- sapply(numcellspos, idf, n=nrow(brain))
print(idf_scores[1:10])
#multiply the idf weight for a gene by the gene expression level for the cell and store in
#new matrix
brain2<-as.data.frame(brain)
idf_vector<- as.vector(idf_scores)
for (i in 1:8956){
brain2[ ,i]<- as.numeric(brain2[,i])*idf_vector[i]
}
cosine.similarity(brain2[1,], brain2[2,])
??cosine.similarity
install.packages("tcR")
library(tcR)
cosine.similarity(brain2[1,], brain2[2,])
install.packages("lsa")
library(lsa)
??cosine
cosine(t(as.matrix(brain2)))
cos_sim_matrix<-cosine(t(as.matrix(brain2)))
save.image("C:/Users/mkw5c/OneDrive/Documents/Capstone/topic modeling and RNA seq/TFIDF environment 11.1.RData")
train = read.csv("train.csv")
test = read.csv('test.csv')
library('dplyr') # data manipulation
library('readr') # input/output
library('data.table') # data manipulation
library('tibble') # data wrangling
library('tidyr') # data wrangling
library('stringr') # string manipulation
library('forcats') # factor manipulation
library('rlang') # data manipulation
# -----Data Exploration------- #
summary(train)
summary(test)
# drop NA rows
newdata <- na.omit(train) # no NA rows
newdata_test <- na.omit(test) # no NA rows
# remove duplicates
train = newdata[!duplicated(newdata), ] # no duplicates
test = newdata_test[!duplicated(newdata_test), ] # no duplicates
# fill the missing value -1 with mode using which.max(x)
for (i in 2:59){
train[,i][train[,i]=='-1'] <- which.max(train[,i])
}
# turn variables ending with cat to factor and bin to logical
train[,grep("cat", names(train))] <-lapply(train[,grep("cat", names(train))], as.factor)
train[,grep("bin", names(train))] <-lapply(train[,grep("bin", names(train))], as.logical)
str(train) # check to see the type of each variable
test[,grep("cat", names(test))] <-lapply(test[,grep("cat", names(test))], as.factor)
test[,grep("bin", names(test))] <-lapply(test[,grep("bin", names(test))], as.logical)
str(test)
train_sample = train[sample(nrow(train), 3000), ]
apply(train_sample,2,unique)
setwd("C:/Users/mkw5c/OneDrive/Documents/SYS6018/competitions/sys6018-competition-safe-driver")
setwd("C:/Users/mkw5c/OneDrive/Documents/SYS6018/competitions/sys6018-competition-safe-driver")
train = read.csv("train.csv")
test = read.csv('test.csv')
library('dplyr') # data manipulation
library('readr') # input/output
library('data.table') # data manipulation
library('tibble') # data wrangling
library('tidyr') # data wrangling
library('stringr') # string manipulation
library('forcats') # factor manipulation
library('rlang') # data manipulation
# -----Data Exploration------- #
summary(train)
summary(test)
# drop NA rows
newdata <- na.omit(train) # no NA rows
newdata_test <- na.omit(test) # no NA rows
train = newdata[!duplicated(newdata), ] # no duplicates
test = newdata_test[!duplicated(newdata_test), ] # no duplicates
for (i in 2:59){
train[,i][train[,i]=='-1'] <- which.max(train[,i])
}
train[,grep("cat", names(train))] <-lapply(train[,grep("cat", names(train))], as.factor)
train[,grep("bin", names(train))] <-lapply(train[,grep("bin", names(train))], as.logical)
str(train) # check to see the type of each variable
test[,grep("cat", names(test))] <-lapply(test[,grep("cat", names(test))], as.factor)
test[,grep("bin", names(test))] <-lapply(test[,grep("bin", names(test))], as.logical)
str(test)
train_sample = train[sample(nrow(train), 3000), ]
apply(train_sample,2,unique)
fit = glm(target~.-ps_car_,family=binomial(link='logit'), data = train_sample)
summary(fit)
fit = glm(target~.,family=binomial(link='logit'), data = train_sample)
summary(fit)
anova(fit)
start<-glm(target ~1,data= train_sample)
fit = glm(target~., data = train_sample)
summary(fit)
anova(fit)
start<-glm(target ~1,data= train_sample)
end<-glm(target~.,data= train_sample)
result.s<-step(start, scope=list(upper=end), direction="both",trace=FALSE)
summary(result.s)
anova(result.s)
driver.lm<- glm(target ~ ps_ind_05_cat + ps_ind_17_bin + ps_reg_02 +
ps_calc_20_bin + ps_car_01_cat + ps_car_08_cat + ps_ind_01 +
ps_reg_03 + ps_ind_04_cat + ps_calc_03 + ps_ind_12_bin +
ps_calc_06, data = train)
cv_error<- cv.glm(train, driver.lm, K = 5)
cv_error$delta
unnormalized.gini.index = function(ground.truth, predicted.probabilities) {
if (length(ground.truth) !=  length(predicted.probabilities))
{
stop("Actual and Predicted need to be equal lengths!")
}
# arrange data into table with columns of index, predicted values, and actual values
gini.table = data.frame(index = c(1:length(ground.truth)), predicted.probabilities, ground.truth)
# sort rows in decreasing order of the predicted values, breaking ties according to the index
gini.table = gini.table[order(-gini.table$predicted.probabilities, gini.table$index), ]
# get the per-row increment for positives accumulated by the model
num.ground.truth.positivies = sum(gini.table$ground.truth)
model.percentage.positives.accumulated = gini.table$ground.truth / num.ground.truth.positivies
# get the per-row increment for positives accumulated by a random guess
random.guess.percentage.positives.accumulated = 1 / nrow(gini.table)
# calculate gini index
gini.sum = cumsum(model.percentage.positives.accumulated - random.guess.percentage.positives.accumulated)
gini.index = sum(gini.sum) / nrow(gini.table)
return(gini.index) }
unnormalized.gini.index(ground.truth = train$target, predicted.probabilities = fitted(driver.lm))
normalized.gini.index = function(ground.truth, predicted.probabilities) {
model.gini.index = unnormalized.gini.index(ground.truth, predicted.probabilities)
optimal.gini.index = unnormalized.gini.index(ground.truth, ground.truth)
return(model.gini.index / optimal.gini.index)}
normalized.gini.index(ground.truth = train$target, predicted.probabilities = fitted(driver.lm))
start<-glm(target ~1,family = binomial(link = "logit"), data= train_sample)
end<-glm(target~.,data= train_sample)
end<-glm(target~., binomial(link = "logit"), data= train_sample)
result.s<-step(start, scope=list(upper=end), direction="both",trace=FALSE)
summary(result.s)
anova(result.s)
driver.lm<- glm(target ~ ps_reg_03 + ps_car_13 + ps_calc_08 + ps_ind_15 +
ps_car_11 + ps_car_03_cat + ps_calc_09 + ps_ind_06_bin, family = binomial(link = "logit"),
data = train)
pred_probs<- predict(driver.lm, data = train, type = "response")
normalized.gini.index(ground.truth = train$target, predicted.probabilities = pred_probs)
summary(result.s)
pred_probs<- predict(driver.lm, newdata = train.test, type = "response")
pred_probs<- predict(driver.lm, newdata = test, type = "response")
train<- sample(595212, 30000, replace = FALSE)
train = read.csv("train.csv")
setwd("C:/Users/mkw5c/OneDrive/Documents/SYS6018/competitions/sys6018-competition-safe-driver")
train = read.csv("train.csv")
test = read.csv('test.csv')
train = read.csv("train.csv")
setwd("C:/Users/mkw5c/OneDrive/Documents/SYS6018/competitions/sys6018-competition-safe-driver")
train = read.csv("train.csv")
